### Idea

_Statistical significance_ is a measure used in hypothesis testing. It is commonly defined in terms of the likelihood, under the assumption of some _null_ hypothesis, of results occurring with at least the significance as those that are measured. For instance, in a drug trial where those taking drug $A$ fare on average better than those on drug $B$, one might calculate the likelihood that such an effect would be found by chance given that the two drugs were in fact equally effective. Significance levels are often given as $p$-values. 

There have been a number of criticisms of such statistical practices and their interpretation, especially by [[Bayesianism|Bayesian]] statisticians. 

In experimental physics, researchers often require significance levels of $5 \sigma$ (5 [[standard deviations]]). This should not be understood as meaning that the chance that this is a mere statistical fluctuation is 1 in 3.5 million, as an incorrect reading of the $p$-value might suggest. Instead, this level has been chosen from experience as making it sufficiently likely that the signal will not disappear as further evidence is collected. Bayesians are typically critical of this $\sigma$ language for its incoherence and argue that background knowledge is employed to allow model comparison, see, for instance ([D'Agostini 03](#DAgostini03)).

### References 

* $n$Cafe: [Fetishizing p-Values](http://golem.ph.utexas.edu/category/2010/09/fetishizing_pvalues.html) by Tom Leinster

* Leland Wilkinson and Task Force on Statistical Inference, Statistical methods in psychology journals: guidelines and explanations, American Psychologist 54 (1999), 594&#8211;604, [pdf](http://www.apa.org/pubs/journals/releases/amp-54-8-594.pdf)

* {#DAgostini03} Giulio D'Agostini, _Bayesian reasoning in data analysis: A critical introduction_, World Scientific Publishing, 2003.