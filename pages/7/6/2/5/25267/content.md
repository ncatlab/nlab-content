
+-- {: .rightHandSide}
+-- {: .toc .clickDown tabindex="0"}
### Context
#### Probability theory
+-- {: .hide}
[[!include measure theory - contents]]
=--
=--
=--



#Contents#
* table of contents
{:toc}

## Idea

In the context of [[machine learning]], *singular learning theory* applies results from [[algebraic geometry]] to [[statistical learning theory]]. In the case of learning algorithms, such as [[deep neural networks]], where there are multiple parameter values corresponding to the same [[statistical distribution]], the [[preimage]] of the target distribution may take the form of a [[singular point|singular]] subspace of the parameter space. Techniques from algebraic geometry may then be applied to study learning with such devices.

## References

Textbook treatments:

* [[Sumio Watanabe]], _Algebraic geometry and statistical learning theory_, CRC Press (2009) &lbrack;[doi:10.1017/CBO9780511800474]( https://doi.org/10.1017/CBO9780511800474)&rbrack;

* [[Sumio Watanabe]], _Mathematical theory of Bayesian statistics_, Cambridge University Press (2018) &lbrack;[ISBN:9780367734817](https://www.routledge.com/Mathematical-Theory-of-Bayesian-Statistics/Watanabe/p/book/9780367734817), [pdf](http://196.189.45.87/bitstream/123456789/36917/1/Sumio%20Watanabe_2018.pdf)&rbrack;

For an informal discussion:

* {#Hoogland} Jesse Hoogland, _Neural networks generalize because of this one weird trick_ ([blog post](https://www.jessehoogland.com/article/neural-networks-generalize-because-of-this-one-weird-trick)); Jesse Hoogland, Filip Sondej, _Spooky action at a distance in the loss landscape_ ([blog post](https://www.lesswrong.com/posts/2N7eEKDuL5sHQou3N/spooky-action-at-a-distance-in-the-loss-landscape)).

For a series of talks and further texts:

* Singular Learning Theory seminar, ([webpage](https://metauni.org/slt/))


