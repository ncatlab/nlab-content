## Idea ##

Unlike traditional logics, which deal with the truth of
propositions, linear logic is often described as dealing
with the availability of resources.  A proposition, if it is
true, remains true no matter how we use that fact in proving
other propositions.  By contrast, in using a resource $A$ to
make available a resource $B$, $A$ itself may be consumed or
otherwise modified.  Linear logic deals with this by
restricting our ability to duplicate or discard resources
freely.  For example, classically we might have
$$\text{have cake}\vdash\text{eat cake}$$
from which we can prove
$$\text{have cake} \wedge \text{have cake}\vdash \text{have cake} \wedge \text{eat cake}$$
which by left contraction (duplication of inputs) yields
$$\text{have cake}\vdash\text{have cake}\wedge\text{eat cake}$$
Linear logic would disallow the contraction step and treat
$\text{have cake}\wedge\text{have cake}\vdash A$ as
meaning that _two_ slices of cake yield $A$, for some value
of $\wedge$ (namely $\otimes$).

Linear logic was introduced in \[1\].  Although it is usually presented in terms of inference rules, it was apparently discovered by Girard while studying [coherent
spaces](http://en.wikipedia.org/wiki/Coherent_space) (not
the topological kind).

## Discussion ##

Probably the best way to explain LL to a category theorist
is to say that its models are $*$-[[star-autonomous category|autonomous categories]] with extra structure (see \[2\]).

Firstly, there is a monoidal tensor product $A \otimes B$
and duals $A^*$ for each $A,B$, while the internal hom
$A\multimap B$ is isomorphic to $(A\otimes B^*)^*$.  There
is a De Morgan dual of the tensor called 'par', with $A
\parr B = (A^*\otimes B^*)^*$.  These model the
'multiplicative' connectives, which roughly speaking
interpret parallelism (via bifunctoriality), while $-^*$
interprets negation.

+--{: .query}
[[Mike Shulman|Mike]]: I've usually seen $(-)^\bot$ for the linear negation; did you choose $(-)^*$ just to emphasize the connection with  $*$-autonomous categories?

[[Finn Lawler|Finn]]: Well, $(-)^*$ above is the duality involution, really -- I haven't quite got to the syntax yet.  But, yes, that's what I mean.

What I might do is move this basic stuff to the $*$-autonomous category page and make this page more about syntax.
=--


The 'additive' connectives $\&$ and $\oplus$, which
correspond more closely to the traditional conjunction and
disjunction, are modelled as usual by products and
coproducts.  Seely notes \[2\] that products are sufficient,
as $*$-autonomy then guarantees the existence of coproducts.

LL recaptures the notion of a resource that can be discarded
or copied arbitrarily by the use of the modal operator $!$:
$!A$ denotes an '$A$-factory', a resource that can produce
zero or more $A$s on demand.  It is modelled using a comonad
$!$ on the underlying $*$-autonomous category that is
(symmetric) monoidal, in the sense that there is an
isomorphism $!A\otimes!B \cong !(A\times B)$.  Since every
$A$ is canonically a symmetric $\times$-comonoid, $!A$ is
then a symmetric $\otimes$-comonoid.

An LL sequent
$$A_1,\ldots,A_n \vdash B_1,\ldots,B_m$$
is interpreted as a morphism
$$ \otimes_i A_i \to \parr_j B_j $$
The comonoid structure on $!A$ then yields the weakening
$$ \Gamma\otimes !A \to \Gamma \otimes I \to \Gamma$$
and contraction
$$ \Gamma\otimes !A \to \Gamma \otimes !A \otimes !A $$
maps.  The corresponding rules are interpreted by
precomposing the interpretation of a sequent with one of
these maps.


## References ##

1. Girard, Jean-Yves, 'Linear logic'.  _Theoretical Computer
   Science_ 50:1, 1987.

2. Seely, R. A. G., 'Linear logic, $*$-autonomous categories
   and cofree coalgebras', _Contemporary Mathematics_ 92,
   1989.  Available at
   <http://www.math.mcgill.ca/rags/nets/llsac.ps.gz>.
