
+-- {: .rightHandSide}
+-- {: .toc .clickDown tabindex="0"}
### Context
#### Differential geometry
+-- {: .hide}
[[!include synthetic differential geometry - contents]]
=--
=--
=--

# Differentiable maps
* table of contents
{: toc}

## Idea

A map is *differentiable* at some point if it can be well approximated by a [[linear map]] near that point.  The approximating linear maps at different points together form the *derivative* of the map.

One can then ask whether the derivative itself is differentiable, and so on.  This leads to a hierarchy of ever more differentiable maps, starting with [[continuous maps]] and progressing through maps that are $n$ times (continuously) differentiable to those that are infinitely differentiable, and finally to those that are [[analytic map|analytic]].  Infinitely differentiable maps are sometimes called *smooth*.

Differentiability is first defined directly for maps between (open subsets of) a [[Cartesian space]].  These differentiable maps can then be used to define the notion of [[differentiable manifold]], and then a more general notion of differentiable map *between* differentiable manifolds, forming a [[category]].  We have a parallel hierarchy of ever more differentiable manifolds and ever more differentiable maps between them.  Since every more differentiable manifold has an [[underlying]] less differentiable manifold, we may always consider maps that are less differentiable than the manifolds between which they run.


## Definitions

### From a Cartesian space to the real numbers

Let $f:U\to \mathbb{R}$ be a function, where $U\subseteq \mathbb{R}^n$ is an [[open subset]].  We say that $f$ is **differentiable** at $x\in U$ if there exists a [[linear map]] $d f_x : \mathbb{R}^n \to \mathbb{R}$ such that

$$ \lim_{h\to 0} \frac{f(x+h)-f(x) - d f_x(h)}{\Vert h\Vert} = 0. $$

We say that $f$ is __differentiable on__ a [[subset]] $I$ of $U$ if $f$ is differentiable at every $x\in U$, and __differentiable__ (tout court) if $f$ is differentiable on all of $U$.

The map $d f_x$ is called the **derivative** or **differential of $f$ at $x$**.  If $n=1$, as in classical one-variable calculus, then $d f_x$ can be identified with a number, and that number is also called the derivative of $f$ at $x$ and often written $f'(x)$.  (In that case, the notation $d f$ is generally still reserved for the corresponding linear map, with its input denoted by $d x$, so that we have $d f = f'(x) d x$.)

Note that $h\in \mathbb{R}^n$, so the limit as $h\to 0$ means that it approaches zero "from all directions at once".  More precisely, for any $\epsilon \gt 0$ there must be an [[open subset]] $V\subseteq U$ containing $x$ such that whenever $x+h\in V$ we have $\frac{f(x+h)-f(x) - d f_x(h)}{\Vert h\Vert} \lt \epsilon$.

An equivalent way to state this definition is to say that
$$ f(x+h) = f(x) + d f_x(h) + E(h){\Vert h\Vert} $$
where $E$ is a function such that $\lim_{h\to 0}E(h) = 0$.  This is easy to see; just let $E(h) = \frac{f(x+h)-f(x) - d f_x(h)}{\Vert h\Vert}$.

Another equivalent way to say it is that
$$ f(x+h) = f(x) + d f_x(h) + E_1(h) h_1 + \cdots + E_n(h) h_n $$
where $E_i$ are functions such that $\lim_{h\to 0}E_i(h) = 0$.  For if this is true, then $E(h) = \frac{1}{\Vert h\Vert}(E_1(h) h_1 + \cdots + E_n(h) h_n)$ satisfies the previous definition.  Conversely, if the previous definition holds, then defining $E_i(h) = \frac{h_i}{\Vert h \Vert} E(h)$ satisfies this definition.

### Partial and directional derivatives

A weaker notion of differentiability is the following: given any $v\in \mathbb{R}^n$, the **directional derivative** of $f:U\to \mathbb{R}$ at $x\in U$ in the direction of $v$ is the limit

$$ \lim_{h\to 0} \frac{f(x+h v)- f(x)}{h}$$

if this exists.  In this case, $h$ is just a real number.  Historically, the term 'directional derivative' was reserved for when $v$ is a [[unit vector]] (or divide the derivative above by $\|v\|$), but the general concept involves less structure and is more important but has no other established name.  If $v$ is a standard basis vector $e_i$, then the directional derivative is called a **[[partial derivative]]** with respect to the corresponding coordinate, and often written $\frac{\partial f}{\partial x_i}$ or $f_{x_i}$.

If $f$ is differentiable at $x$ in the above sense, then $d f_x(v)$ is its directional derivative along $v$.  In particular, the coordinates of $d f_x$ are the partial derivatives of $f$.

In general, $f$ may have all partial derivatives, and even all directional derivatives, without being differentiable; see the examples below.  However, if $f$ has all partial derivatives and they are *continuous* as functions of $x$, then in fact $f$ is differentiable (and indeed continuously differentiable).

### Maps between Cartesian spaces

For $U\subseteq \mathbb{R}^n$, a map $f:U\to \mathbb{R}^m$ is differentiable if each component $f_i : U \to \mathbb{R}$ is differentiable.  In this case, the derivatives of the $f_i$ assemble into a linear map $d f_x: \mathbb{R}^n \to \mathbb{R}^m$.

## Higher differentiability

### Iterated differentiability

For $f:U\to \mathbb{R}^m$, we can regard $d f$ as a function from a subset of $U$ (the points where $f$ is differentiable) to the space $L(\mathbb{R}^n,\mathbb{R}^m)$ of [[linear maps]].  Since $L(\mathbb{R}^n,\mathbb{R}^m) \cong \mathbb{R}^{n m}$ is again a Cartesian space, we can then ask whether $d f$ is differentiable.

We can then iterate, obtaining the following hierarchy of differentiability.  Because iterated differentiability by itself is not very useful, and a differentiable map is necessarily continuous, one generally includes continuity of the last assumed derivatives.

* The map $f$ is __continuous__ or __$C^0$__ if it is a [[continuous map]] between underlying [[topological spaces]].  We begin with this since a differentiable map is necessarily continuous.

* The map $f$ is __continuously differentiable__ or __$C^1$__ on $U$ if it is differentiable at all points of $U$ and the resulting map $d f$ is [[continuous map|continuous]].  (At this point, if we generalize to infinite-dimensional spaces, we get a variety of notions of when the differential is 'continuous'; see [[continuously differentiable map]] for discussion.)

* The map $f$ is __twice differentiable__ if it is differentiable and its derivative $d f$ is differentiable.  A twice differentiable map must be continuously differentiable.  Similarly, $f$ is __twice continuously differentiable__ or __$C^2$__ if it is twice differentiable and the second derivative $d d f$ is continuous.

* By [[recursion]], $f$ is __$n + 1$ times differentiable__ if $f$ is $n$ times differentiable and the $n$th derivative of $f$ is differentiable.  Similarly, $f$ is __$n$ times continuously differentiable__ or __$C^n$__ if $f$ is $n$ times differentiable and the $n$th derivative of $f$ is continuous.

* The map $f$ is __[[smooth map|smooth]]__ or __infinitely differentiable__ or __$C^\infty$__ if it is $n$ times differentiable for all $n$, or equivalently if it is $C^n$ for all $n$.  (There is no difference between infinite differentiability and infinite continuous differentiability.)  One may also define this notion [[coinductive definition|coinductively]]: $f$ is infinitely differentiable if it is differentiable and its derivative $d f$ is infinitely differentiable.

* One step higher, we may ask whether $f$ is [[analytic function|analytic]] or $C^\omega$.

### Symmetry of higher derivatives

If $f:U\to \mathbb{R}^m$ is twice differentiable with $U\subseteq \mathbb{R}^n$, its second derivative
$$d^2 f : U \to L(\mathbb{R}^n,L(\mathbb{R}^n,\mathbb{R}^m)) \cong Bilin(\mathbb{R}^n,\mathbb{R}^n;\mathbb{R}^m)$$
is a function from $U$ into the space of [[bilinear maps]] from $\mathbb{R}^n\times \mathbb{R}^n$ to $\mathbb{R}^m$.  In general, it need not be *symmetric*, i.e. $d^2 f_x(v,w)$ may not equal $d^2f_x(w,v)$.  In terms of partial derivatives, this means that the *mixed partials* $\frac{\partial^2 f}{\partial x_i \partial x_j}$ and $\frac{\partial^2 f}{\partial x_j \partial x_i}$ may not be equal; see below for a counterexample.

It is true, however, that if $f$ is twice *continuously* differentiable, then $d^2f$ is a *symmetric* bilinear map, and the mixed partials are equal.

### Strong higher differentiability

It is possible to define a notion of higher differentiability that implies symmetry of the mixed partials but does not require their continuity.  Given a function $f:U \to \mathbb{R}^m$ which is differentiable in a neighborhood of $x$, say that $f$ is **strongly twice differentiable** at $x$ if there is a bilinear map $\partial^2 f_x : \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}^m$ such that

$$f(x+v+w) - f(x+v) - f(x+w) + f(x) = \partial^2 f_x(v,w) + E(v,w) {|v|}{|w|} $$

where $\lim_{v,w\to 0} E(v,w) = 0$.  The usual proof of symmetry of the mixed partials shows that if $f$ is $C^2$ in a neighborhood of $x$, then it is strongly twice differentiable at $x$.  On the other hand, since the LHS of the equation above is manifestly symmetric in $v$ and $w$, it follows that if $f$ is strongly twice differentiable at $x$ then the bilinear map $\partial^2 f_x$ is also symmetric.  It's easy to see that its matrix consists of the second partial derivatives of $f$, so this implies the mixed partials are symmetric.

Finally, as explained [here](http://mathoverflow.net/a/165733/49), if $f$ is differentiable in a neighborhood of $x$ and strongly twice differentiable at $x$, then it is in fact twice differentiable at $x$ in the sense that $d f: U \to L (\mathbb{R}^n,\mathbb{R}^m)$ is differentiable at $x$, with derivative $\partial^2 f_x$.  It suffices to show that each coordinate of $d f$ is differentiable, so let $w=\delta e_i$, with $e_i$ a unit basis vector and $\delta$ a real number $\neq 0$.  Then we have

$$ E(v,\delta e_i) = \frac{f(x+v+\delta e_i) - f(x+v) - f(x+\delta e_i) + f(x) - \partial^2 f_x(v,\delta w)}{{|v|}{\delta}}$$

Taking the limit as $\delta\to 0$ and using differentiability of $f$ at $x$ and $x+v$ (for sufficiently small $v$), we get

$$ \lim_{\delta \to 0} E(v,\delta e_i) = \frac{d f_{x+v}(e_i) - d f_x(e_i) - \partial^2 f_x(v,e_i)}{{|v|}}. $$

Now take the limit as $v\to 0$; on the left we get $0$ by assumption, so the function $y\mapsto d f_y(e_i)$ is differentiable at $x$ with derivative $\partial^2 f_x(-,e_i)$.  Thus, $d f$ is differentiable at $x$.

### Extra-strong higher differentiability and the chain rule

The condition $f(x+v+w) - f(x+v) - f(x+w) + f(x) = \partial^2 f_x(v,w) + E(v,w) {|v|}{|w|}$ does not, however, imply that $f$ is differentiable or even continuous at $x$.  For instance, it is satisfied by any $\mathbb{Q}$-linear (or even $\mathbb{Z}$-linear) map $\mathbb{R}\to \mathbb{R}$, since then the LHS vanishes identically.  However, by strengthening it a bit we can incorporate single differentiability as well.

Say that $f$ is **extra-strongly twice differentiable** at $x$ if there exists a linear map $d f_x : \mathbb{R}^n \to \mathbb{R}^m$ and a bilinear map $\partial^2 f_x : \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}^m$ such that

$$f(x+v+w+h) - f(x+v) - f(x+w) + f(x) = \partial^2 f_x(v,w) + d f_x(h) + E(v,w,h) \sqrt{{|v|}^2{|w|}^2 + {|h|}^2}.$$

where $\lim_{v,w,h \to 0} E(v,w,h) = 0$.  Setting $v=w=0$ in this equation, we find that $f$ is differentiable at $x$ with derivative $d f_x$.  And setting $h=0$, we find that $f$ is strongly twice differentiable at $x$ in the above sense.  It seems that it might not be differentiable in a neighborhood of $x$, but if it is, then the above argument shows that it is also twice differentiable at $x$ in the usual sense.

Moreover, we can still say that that if $f$ is $C^2$ in a neighborhood of $x$, then it is extra-strongly twice differentiable at $x$.  For then we can write

$$
\begin{aligned}
  f(x+v+w+h) &= f(x+v+w) + d f_{x+v+w}(h) + E {|h|}\\
  &= f(x+v+w) + d f_x(h) + d(d f)_x(v+w,h) + E {|v+w|}{|h|} + E{|h|}
\end{aligned}
$$

and $d(d f)_x(v+w,h)$ can also be incorporated into the error term.

This may seem like a somewhat *ad hoc* modification.  However, the formal sum $\partial^2 f_x + d f_x$ is what should be regarded as the **second differential** of $f$.  We write it like this:

$$d^2f = \partial^2 f + d f = \sum_{i,j} \frac{\partial^2f}{\partial x_i \partial x_j} d x_i \, d x_j + \sum_i \frac{\partial f}{\partial x_i} d^2 x_i. $$

The virtue of this expression is that like the first differential $d f$, but unlike the bilinear map $\partial^2 f$, it satisfies [[Cauchy's invariant rule]].  This means that we can express the [[chain rule]] for second differentials of composite maps simply by substitution: if $y = f(u)$ and $u = g(x)$, then finding $d^2 y$ in terms of $d u$ and $d^2 u$, and $d u$ and $d^2 u$ in terms of $d x$ and $d^2 x$, and substituting, gives the correct expression for $d^2 y$ in terms of $d x$ and $d^2 x$.

In fact, this can be proven using the definition of extra-strong twice differentiability, in essentially exactly the same way that we prove the ordinary chain rule for first derivatives.  We sketch the proof, omitting the explicit error terms.  We can write

$$g(f(x+v+w+h)) - g(f(x+v)) - g(f(x+w)) + g(f(x)) $$

as

$$ g(f(x) + v' + w' + h') - g(f(x) + v') - g(f(x) + w') + g(f(x)) $$

where $v' = f(x+v) - f(x)$ and $w' = f(x+w) - f(x)$ and $h' = f(x+v+w+h) - f(x+v) - f(x+w) + f(x)$.  Now by extra-strong twice differentiability of $g$, this is approximately equal to

$$ \partial^2 g_{f(x)}(v',w') + d g_{f(x)}(h'). $$

But by differentiability of $f$, we have $v' \approx d f_x(v)$ and $w' \approx d f_x(w)$, while by extra-strong twice differentiability of $f$ we have $h' \approx \partial^2 f_x(v,w) + d f_x(h)$.  Thus, we obtain approximately

$$ \partial^2 g_{f(x)}(d f_x(v), d f_x(w)) + d g_{f(x)}(\partial^2 f_x(v,w) + d f_x(h)) $$

which is exactly what we would get by substitution.


### For maps between manifolds

If $X$ and $Y$ are $C^k$-[[manifolds]], then we can define what it means for a map $f:X\to Y$ to be $n$ times differentiable, or $C^n$, for any $n\le k$, by asking that it yield such a map when restricted to any charts.  The most common case is when $X$ and $Y$ are smooth (infinitely differentiable) manifolds, so that we can define $C^n$ functions between them for all $n\le \infty$.  (Analytic manifolds, which are necessary in order to define analyticity of $f$, are somewhat rarer.)

A differentiable map between manifolds induces a map between their [[tangent bundles]] $d f : T X \to T Y$; this operation extends to a [[functor]] from $C^{k+1}$ manifolds and $C^{k+1}$ maps to $C^k$ manifolds and $C^k$ maps.  See [[differentiation]] for more.

## Examples and non-examples

### Differentiability versus partial differentiability

The function $f:\mathbb{R}^2 \to \mathbb{R}$ defined by

$$ f(x,y) =
\begin{cases}
  \frac{y^3}{x^2+y^2} &\quad (x,y) \neq (0,0)\\
  0 &\quad (x,y) = (0,0)
\end{cases}
$$

is continuous everywhere, and has directional derivatives at $(0,0)$ in all directions, but is not differentiable at $(0,0)$.  Note that the directional derivative along the line $y=m x$ is $\frac{m^3}{1+m^2}$, which is not a linear function.

One may wonder whether existence of a linear map $d f_x$ is enough, but this is also not the case.  The function $f:\mathbb{R}^2 \to \mathbb{R}$ defined by

$$ f(x,y) = \begin{cases} \frac{y^3}{x} &\quad x\neq 0\\ 0 &\quad x=0 \end{cases} $$

has all directional derivatives at $(0,0)$ equaling $0$, so that in particular there is a linear map $d f_{(0,0)}$ whose values are the directional derivatives.  But it is not differentiable at $(0,0)$; in fact, it is not even continuous at $(0,0)$.  (Thus it also provides an example of a discontinuous function which has all directional derivatives.)

+--{: .query}
[[Mike Shulman]]: Is there a function that is continuous in a neighborhood of $(0,0)$ *and* has all directional derivatives there equaling $0$, but is not differentiable?
=--

### Differentiability versus continuous and higher differentiability

Let $k$ be a [[natural number]], and consider the function
$$ f_k(x) \coloneqq x^k \sin(1/x) $$
from the [[real line]] to itself, with $f(0) \coloneqq 0$.  Away from $0$, $f_k$ is smooth (even analytic); but at $0$, $f_0$ is not continuous, $f_1$ is continuous but not differentiable, $f_2$ is differentiable but not continuously differentiable, and so on:
*  If $k = 2 n$ is even, then $f_k$ is differentiable $n$ times but not continuously differentiable $n$ times;
*  If $k = 2 n + 1$ is odd, then $f_k$ is continuously differentiable $n$ times but not differentiable $n + 1$ times.

Similarly, in two dimensions we can consider functions such as
$$ f(x,y) = (x^2+y^2)\sin(\frac{1}{\sqrt{x^2+y^2}}).$$
together with $f(0,0) = 0$.  This is smooth away from $0$, and once differentiable at $0$, even in the strong sense that it is well-approximated by a linear function near $0$.  However, its derivative is not continuous at $0$.  In particular, this shows that the converse of the theorem "if the partial derivatives exist and are continuous at a point, then the function is differentiable there" fails.

### Symmetry of the second derivative

The function $f:\mathbb{R}^2 \to \mathbb{R}$ defined by 

$$ f(x,y) = \frac{xy(x^2-y^2)}{x^2+y^2}$$

plus $f(0,0) = 0$, has partial derivatives $\frac{\partial^2f}{\partial x \partial y}$ and $\frac{\partial^2f}{\partial y \partial x}$ that both exist but are not equal at $(0,0)$ (nor are they continuous at $(0,0)$).

### Twice differentiability versus quadratic approximation

While differentiability means approximability by a linear function, twice differentiability does *not* mean approximability by a quadratic function.  For example, the function

$$ f(x) = x^3 \sin(1/x) $$

(with $f(0) =0$, to make it continuous there) is not twice differentiable at $x=0$, but it is well-approximated by the quadratic polynomial $p(x) = 0$ in the sense that their difference is $o(x^2)$ as $x\to 0$.  Even worse, the function

$$ f(x) = e^{-1/x^2} \sin(e^{1/x^2}) $$

is not twice differentiable at $x=0$, but it is well-approximated by a polynomial of *any* finite degree $n$ (namely, the zero polynomial), in the sense that their difference is $o(x^n)$ as $x\to 0$.

In some contexts, it is useful to say that functions such as these have "pointwise second derivatives".  More precisely, we say that a function $f$ has a **pointwise $k^{th}$ derivative** at $a$ if there exists a polynomial $p$ of degree $k$ such that 

$$ \lim_{x\to a} \frac{f(x) - p(x)}{(x-a)^k} = 0. $$

In this case, the pointwise $k^{th}$ derivative is $f^{(k)}_{pt}(a) = p^{(k)}(a)$.  Thus we would say that while $ f(x) = x^3 \sin(1/x) $ does not have a second derivative at $0$, it does have a *pointwise* second derivative at $0$, and $f''_{pt}(0) = 0$.  See e.g. [this MSE answer](http://math.stackexchange.com/a/160383/91608).

### The second derivative as a quadratic form

In the definition of strong twice-differentiability, we cannot replace the symmetric [[bilinear map]] $\partial^2 f_x(v,w)$ by the corresponding [[quadratic form]] $Q_x(v) = \partial^2f_x(v,v)$.  In other words, if we suppose that

$$f(x+2v) - 2 f(x+v) + f(x) = Q_x(v) + E(v) {|v|}^2 $$

where $\lim_{v\to 0} E(v) = 0$, for some quadratic form $Q_x$, it does not follow that $f$ is twice differentiable at $x$, even in one dimension.  The same old counterexample

$$ f(x) = x^3 \sin(1/x) $$

(with $f(0)=0$) works: we have

$$f(0+2v) - 2 f(0+v) + f(0)= 2v^3(4\sin(\frac{1}{2v}) - \sin(\frac{1}{v}))$$

so $E(v) = v (4\sin(\frac{1}{2v}) - \sin(\frac{1}{v})) \to 0$.

## Related concepts

* [[extremum]]

* [[continuous function]], **differentiable function**, [[continuously differentiable function]], [[smooth function]], [[analytic function]]


[[!redirects differentiable map]]
[[!redirects differentiable maps]]
[[!redirects differentiable function]]
[[!redirects differentiable functions]]

[[!redirects twice differentiable map]]
[[!redirects twice differentiable maps]]
[[!redirects twice differentiable function]]
[[!redirects twice differentiable functions]]

[[!redirects C-n map]]
[[!redirects C-n maps]]
[[!redirects C-n function]]
[[!redirects C-n functions]]
[[!redirects C^n map]]
[[!redirects C^n maps]]
[[!redirects C^n function]]
[[!redirects C^n functions]]
[[!redirects C-k map]]
[[!redirects C-k maps]]
[[!redirects C-k function]]
[[!redirects C-k functions]]
[[!redirects C^k map]]
[[!redirects C^k maps]]
[[!redirects C^k function]]
[[!redirects C^k functions]]

[[!redirects derivative]]
[[!redirects derivatives]]

[[!redirects pointwise derivative]]
[[!redirects pointwise derivatives]]
